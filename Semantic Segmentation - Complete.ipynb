{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tqdm\n",
    "!pip3 install pillow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import shutil\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from matplotlib import pyplot as plt\n",
    "from xml.etree import ElementTree as ET\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "urls = ['http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz',\n",
    "        'http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz']\n",
    "\n",
    "def download_and_extract(data_dir, download_dir):\n",
    "    for url in urls:\n",
    "        target_file = url.split('/')[-1]\n",
    "        if target_file not in os.listdir(download_dir):\n",
    "            print('Downloading', url)\n",
    "            urllib.request.urlretrieve(url, os.path.join(download_dir, target_file))\n",
    "            tf = tarfile.open(url.split('/')[-1])\n",
    "            tf.extractall(data_dir)\n",
    "        else:\n",
    "            print('Already downloaded', url)\n",
    "\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "download_and_extract('data', '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimaps_dir = 'data/annotations/trimaps/'\n",
    "\n",
    "maps = [x for x in os.listdir(trimaps_dir) if x[-3:] == 'png']\n",
    "print(len(maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'data/images/'\n",
    "\n",
    "images = [x for x in os.listdir(image_dir) if x[-3:] == 'jpg']\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i in range(0, 4):\n",
    "    index = random.randint(0, len(images) - 1)\n",
    "    image_name = images[index]\n",
    "    map_name = images[index].split('.')[0] + '.png'\n",
    "\n",
    "    plt.subplot(4, 2, 1 + i*2)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(plt.imread(os.path.join(trimaps_dir, map_name)))\n",
    "    plt.subplot(4, 2, 2 + i*2)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(plt.imread(os.path.join(image_dir, image_name)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(os.path.join(trimaps_dir, maps[0]))\n",
    "print(np.unique(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "bucket_name = 'petsdata'\n",
    "training_image = get_image_uri(boto3.Session().region_name, 'semantic-segmentation',\n",
    "                              repo_version='latest')\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['train', 'train_annotation', 'validation', 'validation_annotation']\n",
    "\n",
    "for folder in folders:\n",
    "    if os.path.isdir(folder):\n",
    "        shutil.rmtree(folder)\n",
    "    os.mkdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_file(image):\n",
    "    map_file = image.split('.')[0] + '.png'\n",
    "    assert map_file in maps\n",
    "    return map_file\n",
    "    \n",
    "for image in tqdm(images):\n",
    "    target_set = 'train' if random.randint(0, 99) < 75 else 'validation'\n",
    "    \n",
    "    image_file_path = os.path.join('data/images/', image)\n",
    "    image_target_path = os.path.join(target_set, image)\n",
    "    \n",
    "    map_file_path = os.path.join(trimaps_dir, get_map_file(image))\n",
    "    map_target_path = os.path.join(target_set + '_annotation', get_map_file(image))\n",
    "    \n",
    "    shutil.copy(image_file_path, image_target_path)\n",
    "    shutil.copy(map_file_path, map_target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = os.listdir('train')\n",
    "train_annots = os.listdir('train_annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_annots), len(train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "print('Starting upload..')\n",
    "s3_train_path = sess.upload_data(path='train', bucket=bucket_name, key_prefix='train')\n",
    "print('Training images uploaded')\n",
    "s3_train_annotation_path = sess.upload_data(path='train_annotation', bucket=bucket_name,\n",
    "                                     key_prefix='train_annotation')\n",
    "print('Training Annotations uploaded')\n",
    "s3_validation_path = sess.upload_data(path='validation', bucket=bucket_name,\n",
    "                                      key_prefix='validation')\n",
    "print('Validation images uploaded')\n",
    "s3_validation_annotation_path = sess.upload_data(path='validation_annotation', bucket=bucket_name,\n",
    "                                          key_prefix='validation_annotation')\n",
    "print('Validation Annotations uploaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_validation_annotation_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p3.2xlarge',\n",
    "    train_volume_size=100,\n",
    "    train_max_run=36000,\n",
    "    input_mode='File',\n",
    "    output_path='s3://petsdata/output',\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_hyperparameters(\n",
    "    backbone='resnet-50', # This is the encoder. Other option is resnet-50\n",
    "    algorithm='fcn', # This is the decoder. Other option is 'psp' and 'deeplab'                             \n",
    "    use_pretrained_model='True', # Use the pre-trained model.\n",
    "    crop_size=240, # Size of image random crop.                             \n",
    "    num_classes=4, # Pascal has 21 classes. This is a mandatory parameter.\n",
    "    epochs=10, # Number of epochs to run.\n",
    "    learning_rate=0.0001,                             \n",
    "    optimizer='rmsprop', # Other options include 'adam', 'rmsprop', 'nag', 'adagrad'.\n",
    "    lr_scheduler='poly', # Other options include 'cosine' and 'step'.                           \n",
    "    mini_batch_size=16, # Setup some mini batch size.\n",
    "    validation_mini_batch_size=16,\n",
    "    early_stopping=True, # Turn on early stopping. If OFF, other early stopping parameters are ignored.\n",
    "    early_stopping_patience=3, # Tolerate these many epochs if the mIoU doens't increase.\n",
    "    early_stopping_min_epochs=10, # No matter what, run these many number of epochs.                             \n",
    "    num_training_samples=len(train_images)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3_train_path, distribution='FullyReplicated',\n",
    "                          content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_path, distribution='FullyReplicated',\n",
    "                          content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "\n",
    "train_annotation_data = sagemaker.session.s3_input(s3_train_annotation_path, distribution='FullyReplicated',\n",
    "                          content_type='image/png', s3_data_type='S3Prefix')\n",
    "validation_annotation_data = sagemaker.session.s3_input(s3_validation_annotation_path, distribution='FullyReplicated',\n",
    "                          content_type='image/png', s3_data_type='S3Prefix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_channels = {\n",
    "    'train': train_data,\n",
    "    'train_annotation': train_annotation_data,\n",
    "    'validation': validation_data,\n",
    "    'validation_annotation': validation_annotation_data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n",
    "print('\\nModel deployed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'validation'\n",
    "images = [x for x in os.listdir(image_dir) if x[-3:] == 'jpg']\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model.content_type = 'image/jpeg'\n",
    "deployed_model.accept = 'image/png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "\n",
    "image_path = os.path.join(image_dir, images[index])\n",
    "# image_path = 'dog_cat.jfif'\n",
    "\n",
    "with open(image_path, 'rb') as f:\n",
    "    b = bytearray(f.read())\n",
    "\n",
    "results = deployed_model.predict(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "mask = np.array(Image.open(io.BytesIO(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread(image_path));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget!! You need to delete endpoint or else you will continue to accrue cost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(deployed_model.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
